---
title: FNN、CNN、RNN简介
date: 2025-09-22 15:44:22
permalink: /pages/292667/
categories:
  - 强大的AI
  - 深度学习
tags:
  - 
author: 
  name: Mr.Kusch
  link: https://github.com/kuschzzp
---

## 1. FNN（前馈神经网络）

* 特点：信息单向流动，从输入层到输出层，中间经过一个或多个隐藏层。每层和下一层是全连接。
* 优点：结构简单，容易训练；适合表格类、特征向量类的数据。
* 缺点：无法捕捉空间结构（图像特征）或序列关系（时间、文本）。

--- 

* 你走进快餐店点餐：

    * 输入：汉堡、可乐、薯条。
    * 收银员：输入 → 结账机 → 输出账单。
* **特点**：

    * 收银员不会记住你之前点过啥，每次都当新顾客。
    * 所有顾客（输入）都走一样的“结账流程”。
* **优点**：快，直接。
* **缺点**：没有记忆，你昨天吃的啥，它完全不知道。

👉 **FNN = 没记忆的收银机**。


## 2. CNN（卷积神经网络）

* 特点：通过“卷积核”在局部区域扫描输入，从而提取边缘、纹理等局部特征；参数共享，减少运算量。
* 结构：

    * 卷积层 → 提取特征
    * 池化层 → 下采样，降低维度，增强鲁棒性
    * 全连接层 → 输出分类或预测
* 应用场景：图像识别（人脸识别、目标检测）、语音处理、文本表示。
* 优点：参数量少、效率高，能很好捕捉局部空间信息。
* 缺点：不擅长处理长距离依赖（比如语言中的上下文关系）。

--- 

* 保安看着大楼的监控屏：

    * 他不会一下子看完整栋楼，而是拿着“放大镜”（卷积核），一格一格扫，识别可疑人影。
    * 看完所有小格子后，他能总结出这栋楼里发生了啥。
* **特点**：

    * 参数少，因为一个放大镜（卷积核）就能重复使用。
    * 很擅长发现局部特征，比如人脸、车牌。
* **优点**：对图像、声音很厉害。
* **缺点**：如果坏人从A门溜进去，再在Z门被抓，保安中间的长距离关系可能跟不上。

👉 **CNN = 带放大镜巡逻的保安**。

## 3. RNN（循环神经网络）

* 特点：带“记忆”的网络，按时间顺序逐步处理输入；每一步的状态依赖于前一步的状态。
* 优点：

    * 能处理变长的序列数据。
    * 参数共享，每个时间步用同一套权重。
* 应用场景：机器翻译、文本生成、语音识别、时间序列预测。
* 缺点：

    * 训练时容易出现梯度消失或梯度爆炸。
    * 学习长距离依赖有困难（改进版有 LSTM、GRU）。

---

* 你和一个朋友聊天：

    * 你说：“我今天…”
    * 他记住了“今天”。
    * 你继续说：“吃了…”
    * 他结合上下文，猜到你可能要说“饭”或“面条”。
* **特点**：

    * 他有记忆，会把之前你说的内容带到后面。
    * 每一步对话都依赖于前面。
* **优点**：能理解上下文，适合对话、翻译、时间序列。
* **缺点**：

    * 话说太久，他会“记忆力衰退”（梯度消失）。
    * 有时容易“记混”（梯度爆炸）。
    * 需要升级版朋友：**LSTM / GRU**，记忆力更强。

👉 **RNN = 一个有点健忘，但能连贯听故事的朋友**。


| 网络类型    | 全称                           | 核心特点         | 主要应用          | 优缺点               |
| ------- | ---------------------------- | ------------ | ------------- | ----------------- |
| FNN | Feedforward Neural Network   | 前馈，全连接，结构简单  | 表格数据、基础分类     | 易用，但无法处理空间/序列信息   |
| CNN | Convolutional Neural Network | 卷积核提特征，局部感受野 | 图像识别、语音识别     | 参数少、提空间特征强；长序列依赖差 |
| RNN | Recurrent Neural Network     | 循环结构，能记忆序列   | NLP、语音、时间序列预测 | 适合序列，但易梯度消失，长依赖难学 |
