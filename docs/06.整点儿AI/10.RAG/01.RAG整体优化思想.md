---
title: RAG整体优化思想
date: 2024-11-10 15:09:35
permalink: /pages/45b980/
categories:
  - 整点儿AI
  - RAG
tags:
  - AI
author:
  name: Mr.Kusch
  link: https://github.com/kuschzzp
---

## RAG

优化 RAG 系统的每个阶段有助于提高检索精度和生成质量，使系统回答更准确、上下文相关。以下是一些常见的优化方法：

### 1. **检索阶段优化**

- **提高检索器的精度**：
    - **Embedding 精调**：使用带有微调的嵌入模型（如 Sentence-BERT）来生成更精准的文本表示向量，可以提高相关性匹配的效果。
    - **基于知识的预训练**：在检索模型上预训练领域特定的语料，这样检索器可以更好地理解该领域的专业术语。
    - **多阶段检索**：采用粗筛+精筛的检索流程。粗筛器先选出较大范围的候选内容，再使用精筛器（如交互式检索模型）对候选内容做更细致的排序。
    - **Query Expansion**：在检索时扩展查询词，比如加入同义词或用户常用词，以捕获更多相关的内容。
    - **知识图谱**：在检索时可以考虑去知识图谱中检索相关实体或关系，以丰富检索内容。

- **动态检索**：
    - **用户意图识别**：如果 RAG 系统支持多轮对话，可以根据对话上下文推测用户意图，动态调整检索内容。
    - **重排检索结果**：根据生成模型的反馈，对检索结果做二次排序，以选择最符合生成模型所需信息的文档。

- **知识库优化**：
    - **定期更新**：知识库中的内容应该定期更新，以确保检索到最新信息。
    - **去噪和聚类**：对知识库内容进行去重和聚类，避免重复和噪声信息干扰检索结果。
    - **片段级索引**：将长文档分成若干有意义的片段进行索引，以便检索到更细粒度的信息，减少无关内容带来的误差。

### 2. **生成阶段优化**

- **生成模型调优**：
    - **微调生成模型**：在特定领域的问答语料上对生成模型进行微调，使其生成内容更贴近目标应用场景的语言风格和信息需求。
    - **加强信息引导**：将检索到的信息嵌入至 prompt 时，可以加入特定的模板或关键词，以增强模型生成的指导性。例如，指定检索到的信息来源，提升准确性。
    - **冷启动策略**：为生成模型预设一些常见问题和其关联的背景内容，这样可以避免生成不准确的回答。

- **上下文增强**：
    - **多轮生成反馈**：在生成过程中，对不确定的生成结果进行多轮反馈，从而逐步校正和提高回答的质量。
    - **动态上下文管理**：如果是多轮对话场景，可以基于当前上下文动态调整检索到的内容，确保生成内容对话流畅、一致。
    - **加权信息融合**：将生成模型对不同检索结果的响应进行加权处理，使得相关性较高的信息在生成内容中更突出。

- **输出质量控制**：
    - **过滤和后处理**：对生成模型输出的内容进行过滤，排除低质量或不相关的部分。可以引入关键词或句式检查来提升回答的连贯性。
    - **自我监督校正**：在生成过程中，引入“自我监督”机制，让模型在输出前自我检查内容的一致性和逻辑性。
    - **评估和反馈机制**：引入外部或人工评估生成的回答质量，以便对模型进行持续改进。

### 3. **检索和生成阶段的协同优化**

- **联合训练**：可以考虑在检索模型和生成模型上联合微调，让二者在共同任务上达到更高的协同效果。
- **Prompt 设计优化**：根据检索内容的长度和复杂度，动态调整 prompt 的格式，使生成模型更好地理解和利用检索信息。
- **基于生成反馈的检索优化**：在生成模型对检索结果的使用过程中，持续记录和分析生成内容中对检索信息的引用情况，为检索阶段的优化提供依据。

## 关于RAG和微调的选择

如果你的数据资料是文献、文档资料，那么你可以选择使用 RAG 模型，因为 RAG 模型是基于检索的生成模型，可以更好地利用文档库中的信息。

而如果你的数据资料是对话数据（QA对话），那么你可以选择使用STF微调的生成模型，因为对话数据更适合生成模型的学习方式。

> 目前LLMs应用落地实际技术：
> 1. 提示词工程
> 2. RAG
> 3. 微调
> 4. 预训练模型  
> 目前大部分实践都是前三种结合使用。
